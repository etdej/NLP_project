{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'/Users/rubenstern/Desktop/NYU/Fall2017/NLP/NLP_project/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from data_processing.extract import *\n",
    "from models import Char_CNN_Small\n",
    "from models import tools as tls\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy import random\n",
    "\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'models.Char_CNN_Small' from '/Users/rubenstern/Desktop/NYU/Fall2017/NLP/NLP_project/models/Char_CNN_Small.py'>"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(tls)\n",
    "importlib.reload(Char_CNN_Small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alphabet = [' ','a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't',\n",
    "            'u', 'v' ,'w', 'x', 'y', 'z', '0', '1', '2','3', '4', '5', '6', '7','8','9','-', ';', '.', '!', '?', ':',\n",
    "            '\\'', '\\\\', '|', '_', '@', '#', '$', '%', '\\^', '&', '*','\\'', '\\~', '+', '-', '=', '<', '>','(', ')',\n",
    "            '[',']', '{', '}']\n",
    "\n",
    "indexing = { letter : i+1 for i, letter in enumerate(alphabet)}\n",
    "indexing['UNK'] = len(alphabet)\n",
    "indexing['No_letter'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l0 = 1014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating dataset\n",
      "generating dataset done\n"
     ]
    }
   ],
   "source": [
    "## generate dataset\n",
    "print(\"generating dataset\")\n",
    "data_path='/Users/rubenstern/Desktop/NYU/Fall2017/NLP/NLP_project/'\n",
    "training_set, validation_set = dataGenerator(data_path, binary=True, max_length=l0)\n",
    "print(\"generating dataset done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.optim.adam.Adam at 0x11cc8ec18>"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyper Parameters\n",
    "\n",
    "alphabet_size = len(alphabet) + 1\n",
    "nb_classes = 2\n",
    "batch_size = 1\n",
    "\n",
    "learning_rate = 1e-5\n",
    "num_epochs = 10\n",
    "\n",
    "# Build, initialize model\n",
    "model = Char_CNN_Small.Char_CNN_Small(l0, alphabet_size, nb_classes, batch_size)\n",
    "# model.init_weights()\n",
    "\n",
    "# Loss and Optimizer\n",
    "loss = nn.BCELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Char_CNN_Small (\n",
      "  (max_pool): MaxPool1d (size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  (relu): ReLU ()\n",
      "  (selu): SELU\n",
      "  (dropout): Dropout (p = 0)\n",
      "  (conv1): Conv1d(68, 4, kernel_size=(7,), stride=(1,))\n",
      "  (conv2): Conv1d(4, 8, kernel_size=(7,), stride=(1,))\n",
      "  (conv3): Conv1d(8, 8, kernel_size=(3,), stride=(1,))\n",
      "  (conv4): Conv1d(8, 8, kernel_size=(3,), stride=(1,))\n",
      "  (conv5): Conv1d(8, 8, kernel_size=(3,), stride=(1,))\n",
      "  (conv6): Conv1d(8, 8, kernel_size=(3,), stride=(1,))\n",
      "  (linear1): Linear (272 -> 32)\n",
      "  (linear2): Linear (32 -> 32)\n",
      "  (classifier): Linear (32 -> 1)\n",
      "  (sigmoid): Sigmoid ()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "training_iter = data_iter(training_set, batch_size)\n",
    "train_eval_iter = eval_iter(training_set[:256], batch_size)\n",
    "validation_iter = eval_iter(validation_set[:128], batch_size)\n",
    "\n",
    "#total_batches = int(len(training_set) / batch_size)\n",
    "total_batches = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6945391297340393\n",
      "begin print\n",
      "Epoch 0; Step 0; Loss 0.694539; Train acc: 0.496094; Dev acc 0.460938\n",
      "0.6904253363609314\n",
      "0.6926764249801636\n",
      "0.6929404735565186\n",
      "0.6944329738616943\n",
      "0.6932066679000854\n",
      "0.6909253001213074\n",
      "0.693667471408844\n",
      "0.6923845410346985\n",
      "0.6937474608421326\n",
      "0.6932423114776611\n",
      "0.692127525806427\n",
      "0.6947020292282104\n",
      "0.6970716118812561\n",
      "0.693532407283783\n",
      "0.6950538754463196\n",
      "0.6972139477729797\n",
      "0.6965385675430298\n",
      "0.6932623386383057\n",
      "0.6913917064666748\n",
      "0.6913783550262451\n",
      "0.6944062113761902\n",
      "0.6921602487564087\n",
      "0.6948409080505371\n",
      "0.6929049491882324\n",
      "0.6927444338798523\n",
      "0.6958839297294617\n",
      "0.6954659819602966\n",
      "0.691408097743988\n",
      "0.6905458569526672\n",
      "0.6888084411621094\n",
      "0.6936265230178833\n",
      "0.6917945742607117\n",
      "0.6908871531486511\n",
      "0.6961296200752258\n",
      "0.695277214050293\n",
      "0.6951888203620911\n",
      "0.6908683776855469\n",
      "0.6923823952674866\n",
      "0.690858006477356\n",
      "0.6961585283279419\n",
      "0.6973813772201538\n",
      "0.6933650374412537\n",
      "0.6889550685882568\n",
      "0.6953619122505188\n",
      "0.6890974044799805\n",
      "0.6981903910636902\n",
      "0.6885726451873779\n",
      "0.6979327201843262\n",
      "0.6970584392547607\n",
      "0.6892187595367432\n",
      "0.6975378394126892\n",
      "0.6893317699432373\n",
      "0.6878576874732971\n",
      "0.6980020403862\n",
      "0.6915251016616821\n",
      "0.6967906355857849\n",
      "0.6962479948997498\n",
      "0.6934286952018738\n",
      "0.6979663372039795\n",
      "0.6885955333709717\n",
      "0.6883264183998108\n",
      "0.6983056664466858\n",
      "0.6993046402931213\n",
      "0.696386456489563\n",
      "0.6902310252189636\n",
      "0.6975456476211548\n",
      "0.6912102103233337\n",
      "0.6929038763046265\n",
      "0.6959998607635498\n",
      "0.6915122270584106\n",
      "0.6889238357543945\n",
      "0.6985183954238892\n",
      "0.6988534331321716\n",
      "0.695311963558197\n",
      "0.688134491443634\n",
      "0.6913486123085022\n",
      "0.6889100670814514\n",
      "0.6989542245864868\n",
      "0.6979970335960388\n",
      "0.6895859241485596\n",
      "0.6946893930435181\n",
      "0.689394474029541\n",
      "0.6910061836242676\n",
      "0.6907457113265991\n",
      "0.6895595788955688\n",
      "0.6971034407615662\n",
      "0.6885945796966553\n",
      "0.6881486177444458\n",
      "0.6914563179016113\n",
      "0.6864706873893738\n",
      "0.6986557245254517\n",
      "0.6883329749107361\n",
      "0.6900448203086853\n",
      "0.6901476383209229\n",
      "0.6865285634994507\n",
      "0.7003849744796753\n",
      "0.6992042660713196\n",
      "0.686033308506012\n",
      "0.687641441822052\n",
      "0.6969133019447327\n",
      "begin print\n",
      "Epoch 1; Step 100; Loss 0.696913; Train acc: 0.523438; Dev acc 0.515625\n",
      "0.6899088621139526\n",
      "0.6859411597251892\n",
      "0.6881093382835388\n",
      "0.6856420040130615\n",
      "0.6839821934700012\n",
      "0.7017707824707031\n",
      "0.7036944627761841\n",
      "0.701760470867157\n",
      "0.6845213174819946\n",
      "0.6863753795623779\n",
      "0.685418963432312\n",
      "0.6859373450279236\n",
      "0.6840782165527344\n",
      "0.6836381554603577\n",
      "0.7030357122421265\n",
      "0.6847371459007263\n",
      "0.7047277092933655\n",
      "0.7027997374534607\n",
      "0.6821931600570679\n",
      "0.7043784856796265\n",
      "0.7040278315544128\n",
      "0.7031678557395935\n",
      "0.7044754028320312\n",
      "0.6836360096931458\n",
      "0.6785274744033813\n",
      "0.6840042471885681\n",
      "0.7043711543083191\n",
      "0.6823443174362183\n",
      "0.7040687203407288\n",
      "0.7064573764801025\n",
      "0.7056994438171387\n",
      "0.6837868094444275\n",
      "0.705382764339447\n",
      "0.6823921203613281\n",
      "0.6838561296463013\n",
      "0.7011932134628296\n",
      "0.7038928866386414\n",
      "0.6834449768066406\n",
      "0.6817834973335266\n",
      "0.6807371973991394\n",
      "0.6835066080093384\n",
      "0.7069427371025085\n",
      "0.70436030626297\n",
      "0.6821656823158264\n",
      "0.702354371547699\n",
      "0.7036830186843872\n",
      "0.6814616918563843\n",
      "0.6817671060562134\n",
      "0.7048983573913574\n",
      "0.6842331290245056\n",
      "0.6805635690689087\n",
      "0.6800522208213806\n",
      "0.7062400579452515\n",
      "0.70660001039505\n",
      "0.703464150428772\n",
      "0.6814689636230469\n",
      "0.6818345785140991\n",
      "0.6814110279083252\n",
      "0.6813693046569824\n",
      "0.682407557964325\n",
      "0.7068049907684326\n",
      "0.6812098026275635\n",
      "0.6802342534065247\n",
      "0.6782277822494507\n",
      "0.6794130802154541\n",
      "0.707323431968689\n",
      "0.6785361766815186\n",
      "0.7071809768676758\n",
      "0.7081770300865173\n",
      "0.7044638395309448\n",
      "0.7092888355255127\n",
      "0.7048588991165161\n",
      "0.7045546174049377\n",
      "0.6785126328468323\n",
      "0.7060783505439758\n",
      "0.7090405225753784\n",
      "0.7044469714164734\n",
      "0.6789812445640564\n",
      "0.6821114420890808\n",
      "0.679654598236084\n",
      "0.7080710530281067\n",
      "0.680392861366272\n",
      "0.6776495575904846\n",
      "0.6780841946601868\n",
      "0.7062485218048096\n",
      "0.7034546136856079\n",
      "0.7081316709518433\n",
      "0.6824599504470825\n",
      "0.6804498434066772\n",
      "0.7075521945953369\n",
      "0.7065693140029907\n",
      "0.6791440844535828\n",
      "0.679237425327301\n",
      "0.6796460151672363\n",
      "0.7077319622039795\n",
      "0.7057275772094727\n",
      "0.7059659361839294\n",
      "0.6812569499015808\n",
      "0.6800457239151001\n",
      "0.6782894730567932\n",
      "begin print\n",
      "Epoch 2; Step 200; Loss 0.678289; Train acc: 0.523438; Dev acc 0.515625\n",
      "0.679704487323761\n",
      "0.7058051824569702\n",
      "0.6800272464752197\n",
      "0.7059063911437988\n",
      "0.7080324292182922\n",
      "0.6794854998588562\n",
      "0.6809043884277344\n",
      "0.6798986792564392\n",
      "0.7081252932548523\n",
      "0.6809229254722595\n",
      "0.7049092054367065\n",
      "0.6803967952728271\n",
      "0.6797617673873901\n",
      "0.7079833149909973\n",
      "0.6788250803947449\n",
      "0.7073907852172852\n",
      "0.7081621885299683\n",
      "0.6768527626991272\n",
      "0.7095876336097717\n",
      "0.6797664761543274\n",
      "0.7083349823951721\n",
      "0.7099896669387817\n",
      "0.678558349609375\n",
      "0.7088919281959534\n",
      "0.6783591508865356\n",
      "0.6786530613899231\n",
      "0.6784270405769348\n",
      "0.6783761382102966\n",
      "0.7066745758056641\n",
      "0.7091082334518433\n",
      "0.6792626976966858\n",
      "0.7067797183990479\n",
      "0.7079311609268188\n",
      "0.7085990309715271\n",
      "0.7075628638267517\n",
      "0.7083206176757812\n",
      "0.6805171966552734\n",
      "0.6818369030952454\n",
      "0.6793821454048157\n",
      "0.6805289387702942\n",
      "0.6773591041564941\n",
      "0.7055103182792664\n",
      "0.7085370421409607\n",
      "0.7067970037460327\n",
      "0.6806011199951172\n",
      "0.7088663578033447\n",
      "0.7086930871009827\n",
      "0.6798356175422668\n",
      "0.6798905730247498\n",
      "0.7053612470626831\n",
      "0.6769351363182068\n",
      "0.7051079869270325\n",
      "0.6779223680496216\n",
      "0.6806431412696838\n",
      "0.6799713969230652\n",
      "0.6794384717941284\n",
      "0.7069361209869385\n",
      "0.6775636672973633\n",
      "0.7076697945594788\n",
      "0.6785445809364319\n",
      "0.7088536620140076\n",
      "0.7069322466850281\n",
      "0.6778213977813721\n",
      "0.7080461382865906\n",
      "0.677520215511322\n",
      "0.7089416980743408\n",
      "0.7097369432449341\n",
      "0.7063102126121521\n",
      "0.7072819471359253\n",
      "0.7081189751625061\n",
      "0.7095960974693298\n",
      "0.6811158061027527\n",
      "0.6814318895339966\n",
      "0.6768537163734436\n",
      "0.682298481464386\n",
      "0.6794291734695435\n",
      "0.706938624382019\n",
      "0.7045007348060608\n",
      "0.7058468461036682\n",
      "0.7050468325614929\n",
      "0.7081887722015381\n",
      "0.6823076605796814\n",
      "0.6795934438705444\n",
      "0.7037355303764343\n",
      "0.6783692240715027\n",
      "0.6786413192749023\n",
      "0.7023364305496216\n",
      "0.7072211503982544\n",
      "0.6824868321418762\n",
      "0.7053201198577881\n",
      "0.7061589956283569\n",
      "0.7081660628318787\n",
      "0.6816293597221375\n",
      "0.6807954907417297\n",
      "0.6818827390670776\n",
      "0.7044805884361267\n",
      "0.681075394153595\n",
      "0.6794531345367432\n",
      "0.6808345913887024\n",
      "0.6816884279251099\n",
      "begin print\n",
      "Epoch 3; Step 300; Loss 0.681688; Train acc: 0.523438; Dev acc 0.515625\n",
      "0.6813967823982239\n",
      "0.6792327165603638\n",
      "0.703406572341919\n",
      "0.6809182167053223\n",
      "0.6821222901344299\n",
      "0.6797403693199158\n",
      "0.7102814316749573\n",
      "0.6779882311820984\n",
      "0.6781682968139648\n",
      "0.7104164958000183\n",
      "0.7102429866790771\n",
      "0.7062810063362122\n",
      "0.6787384748458862\n",
      "0.7069295644760132\n",
      "0.7101636528968811\n",
      "0.7102182507514954\n",
      "0.7090566158294678\n",
      "0.7072577476501465\n",
      "0.6765209436416626\n",
      "0.6788434982299805\n",
      "0.6766549348831177\n",
      "0.6775393486022949\n",
      "0.6783847212791443\n",
      "0.7061448693275452\n",
      "0.7092393040657043\n",
      "0.7083979249000549\n",
      "0.7087960243225098\n",
      "0.6778579354286194\n",
      "0.7097851634025574\n",
      "0.7053733468055725\n",
      "0.7075644135475159\n",
      "0.6812299489974976\n",
      "0.680948793888092\n",
      "0.6782623529434204\n",
      "0.675658643245697\n",
      "0.7079960107803345\n",
      "0.7076252698898315\n",
      "0.7056978940963745\n",
      "0.7058817744255066\n",
      "0.7079432606697083\n",
      "0.7067746520042419\n",
      "0.6834626793861389\n",
      "0.6821603775024414\n",
      "0.678792417049408\n",
      "0.7065033912658691\n",
      "0.6814196109771729\n",
      "0.6812556385993958\n",
      "0.6804941296577454\n",
      "0.6793615818023682\n",
      "0.6803222894668579\n",
      "0.679502546787262\n",
      "0.6810570359230042\n",
      "0.6808941960334778\n",
      "0.70616215467453\n",
      "0.7053879499435425\n",
      "0.709074079990387\n",
      "0.6789165139198303\n",
      "0.7099927067756653\n",
      "0.7053523659706116\n",
      "0.6777142286300659\n",
      "0.6787060499191284\n",
      "0.7066011428833008\n",
      "0.6796941161155701\n",
      "0.6793147325515747\n",
      "0.6765459179878235\n",
      "0.6768782138824463\n",
      "0.6768465638160706\n",
      "0.7109876871109009\n",
      "0.7105885148048401\n",
      "0.68058842420578\n",
      "0.7088354825973511\n",
      "0.7105112671852112\n",
      "0.676677942276001\n",
      "0.6787071228027344\n",
      "0.7108986377716064\n",
      "0.6757374405860901\n",
      "0.7087079882621765\n",
      "0.7086824178695679\n",
      "0.7079641222953796\n",
      "0.67562335729599\n",
      "0.7093120813369751\n",
      "0.7079903483390808\n",
      "0.6748230457305908\n",
      "0.6762630343437195\n",
      "0.6776658892631531\n",
      "0.6761451363563538\n",
      "0.708050012588501\n",
      "0.6776989698410034\n",
      "0.6760318875312805\n",
      "0.6768679022789001\n",
      "0.6764248013496399\n",
      "0.7108890414237976\n",
      "0.6765265464782715\n",
      "0.676075279712677\n",
      "0.6733883023262024\n",
      "0.676222026348114\n",
      "0.6772687435150146\n",
      "0.7084982991218567\n",
      "0.7131279110908508\n",
      "0.7121751308441162\n",
      "begin print\n",
      "Epoch 4; Step 400; Loss 0.712175; Train acc: 0.523438; Dev acc 0.515625\n",
      "0.6748973727226257\n",
      "0.7133187055587769\n",
      "0.7111392617225647\n",
      "0.7113581299781799\n",
      "0.6761960983276367\n",
      "0.7130393385887146\n",
      "0.677396297454834\n",
      "0.7127094864845276\n",
      "0.7106510996818542\n",
      "0.6749346852302551\n",
      "0.7100032567977905\n",
      "0.7116913199424744\n",
      "0.7119346857070923\n",
      "0.7086717486381531\n",
      "0.7121890783309937\n",
      "0.6728088855743408\n",
      "0.674422025680542\n",
      "0.710324227809906\n",
      "0.6746616363525391\n",
      "0.6779780387878418\n",
      "0.7076879143714905\n",
      "0.7092694640159607\n",
      "0.6775296330451965\n",
      "0.6776025295257568\n",
      "0.7105119824409485\n",
      "0.711087703704834\n",
      "0.6789345145225525\n",
      "0.6765730977058411\n",
      "0.7109574675559998\n",
      "0.6787648797035217\n",
      "0.6765930652618408\n",
      "0.6766852140426636\n",
      "0.6748160123825073\n",
      "0.7091106176376343\n",
      "0.6746858954429626\n",
      "0.7114794254302979\n",
      "0.7123284935951233\n",
      "0.6766095757484436\n",
      "0.710170567035675\n",
      "0.6753126382827759\n",
      "0.6747305989265442\n",
      "0.7114478349685669\n",
      "0.6750485897064209\n",
      "0.7108206152915955\n",
      "0.6758853197097778\n",
      "0.6763349771499634\n",
      "0.6743578910827637\n",
      "0.6756986975669861\n",
      "0.6770334243774414\n",
      "0.7093873023986816\n",
      "0.6743193864822388\n",
      "0.6731350421905518\n",
      "0.7126427888870239\n",
      "0.7111770510673523\n",
      "0.673837423324585\n",
      "0.6716464757919312\n",
      "0.6728381514549255\n",
      "0.7114804983139038\n",
      "0.7107051014900208\n",
      "0.6739388108253479\n",
      "0.713487446308136\n",
      "0.6736805438995361\n",
      "0.6721486449241638\n",
      "0.6721680164337158\n",
      "0.6722282767295837\n",
      "0.7127441763877869\n",
      "0.7141802906990051\n",
      "0.6722034811973572\n",
      "0.6715093851089478\n",
      "0.6729817390441895\n",
      "0.7167600989341736\n",
      "0.7168391942977905\n",
      "0.6746362447738647\n",
      "0.7164682745933533\n",
      "0.7133771181106567\n",
      "0.6722226738929749\n",
      "0.6702970862388611\n",
      "0.7157105803489685\n",
      "0.6685838103294373\n",
      "0.6730628609657288\n",
      "0.6696329712867737\n",
      "0.6701914668083191\n",
      "0.7148347496986389\n",
      "0.671370804309845\n",
      "0.7139170169830322\n",
      "0.7160004377365112\n",
      "0.7152007818222046\n",
      "0.6703593134880066\n",
      "0.714998722076416\n",
      "0.7176885008811951\n",
      "0.7146917581558228\n",
      "0.6722464561462402\n",
      "0.6692135334014893\n",
      "0.6706724762916565\n",
      "0.6720445156097412\n",
      "0.6678518652915955\n",
      "0.6708672642707825\n",
      "0.7163625955581665\n",
      "0.7181615233421326\n",
      "0.7166160345077515\n",
      "begin print\n",
      "Epoch 5; Step 500; Loss 0.716616; Train acc: 0.523438; Dev acc 0.515625\n",
      "0.6717314124107361\n",
      "0.7139636278152466\n",
      "0.7190619111061096\n",
      "0.7163512706756592\n",
      "0.7161082625389099\n",
      "0.714580774307251\n",
      "0.7164637446403503\n",
      "0.7166218161582947\n",
      "0.7147782444953918\n",
      "0.6712355017662048\n",
      "0.7169063091278076\n",
      "0.7131720185279846\n",
      "0.6718531250953674\n",
      "0.6705865859985352\n",
      "0.671953022480011\n",
      "0.6741137504577637\n",
      "0.6717104911804199\n",
      "0.6722226738929749\n",
      "0.6725408434867859\n",
      "0.7145373225212097\n",
      "0.7128466367721558\n",
      "0.6764546632766724\n",
      "0.6717576384544373\n",
      "0.7161090970039368\n",
      "0.6723844408988953\n",
      "0.6708239912986755\n",
      "0.7107900381088257\n",
      "0.672137439250946\n",
      "0.6727019548416138\n",
      "0.6716539263725281\n",
      "0.670404314994812\n",
      "0.6701371669769287\n",
      "0.6708979606628418\n",
      "0.6686452031135559\n",
      "0.668811559677124\n",
      "0.6751625537872314\n",
      "0.7188197374343872\n",
      "0.6696015000343323\n",
      "0.6656221151351929\n",
      "0.6701377034187317\n",
      "0.7172785997390747\n",
      "0.721591055393219\n",
      "0.6663936376571655\n",
      "0.7200270295143127\n",
      "0.7185091972351074\n",
      "0.7193193435668945\n",
      "0.6673547625541687\n",
      "0.7190799117088318\n",
      "0.7193883657455444\n",
      "0.7193132638931274\n",
      "0.6678652167320251\n",
      "0.6681810617446899\n",
      "0.6684662103652954\n",
      "0.7197997570037842\n",
      "0.7180473804473877\n",
      "0.6675853729248047\n",
      "0.6663801670074463\n",
      "0.6672266125679016\n",
      "0.7205907106399536\n",
      "0.7195031642913818\n",
      "0.7202920913696289\n",
      "0.6679766178131104\n",
      "0.6666824221611023\n",
      "0.6678670644760132\n",
      "0.666358232498169\n",
      "0.7201563715934753\n",
      "0.6694528460502625\n",
      "0.6661075949668884\n",
      "0.7199294567108154\n",
      "0.7214967608451843\n",
      "0.6680635213851929\n",
      "0.667137622833252\n",
      "0.6651691198348999\n",
      "0.721958339214325\n",
      "0.7221812605857849\n",
      "0.7182897925376892\n",
      "0.6685877442359924\n",
      "0.6673294305801392\n",
      "0.6661730408668518\n",
      "0.7208067774772644\n",
      "0.6656821966171265\n",
      "0.6675487756729126\n",
      "0.6639912724494934\n",
      "0.6644036173820496\n",
      "0.7220994234085083\n",
      "0.720794141292572\n",
      "0.6654382348060608\n",
      "0.7217097878456116\n",
      "0.7213051915168762\n",
      "0.6636945605278015\n",
      "0.6647360324859619\n",
      "0.7220031023025513\n",
      "0.7219275236129761\n",
      "0.6657833456993103\n",
      "0.722909152507782\n",
      "0.7240681648254395\n",
      "0.6643874049186707\n",
      "0.7231598496437073\n",
      "0.7217504978179932\n",
      "0.7223257422447205\n",
      "begin print\n",
      "Epoch 6; Step 600; Loss 0.722326; Train acc: 0.523438; Dev acc 0.515625\n",
      "0.7237661480903625\n",
      "0.7226938009262085\n",
      "0.6656990051269531\n",
      "0.6667835712432861\n",
      "0.7238515615463257\n",
      "0.7219973206520081\n",
      "0.6687536239624023\n",
      "0.7209534645080566\n",
      "0.7165959477424622\n",
      "0.6663315296173096\n",
      "0.7171382904052734\n",
      "0.6648135185241699\n",
      "0.6688716411590576\n",
      "0.7182820439338684\n",
      "0.6674452424049377\n",
      "0.7177372574806213\n",
      "0.6672555208206177\n",
      "0.7189574241638184\n",
      "0.7157567739486694\n",
      "0.6662549376487732\n",
      "0.6691073775291443\n",
      "0.6686687469482422\n",
      "0.7188648581504822\n",
      "0.6678540706634521\n",
      "0.718864381313324\n",
      "0.6664183735847473\n",
      "0.6687248945236206\n",
      "0.6684850454330444\n",
      "0.7218084335327148\n",
      "0.6694707870483398\n",
      "0.6681021451950073\n",
      "0.6679463386535645\n",
      "0.6663450002670288\n",
      "0.7207199931144714\n",
      "0.7195057272911072\n",
      "0.7207065224647522\n",
      "0.6673331260681152\n",
      "0.6678094267845154\n",
      "0.6681700348854065\n",
      "0.6674621105194092\n",
      "0.7206649780273438\n",
      "0.6671930551528931\n",
      "0.6663119196891785\n",
      "0.6644387245178223\n",
      "0.6671961545944214\n",
      "0.7223338484764099\n",
      "0.7227221727371216\n",
      "0.7216662168502808\n",
      "0.6654510498046875\n",
      "0.6659656763076782\n",
      "0.665364146232605\n",
      "0.6621799468994141\n",
      "0.6637899279594421\n",
      "0.72280353307724\n",
      "0.7234659194946289\n",
      "0.7197524905204773\n",
      "0.7232587337493896\n",
      "0.6644796133041382\n",
      "0.6627576351165771\n",
      "0.6620774269104004\n",
      "0.6657729148864746\n",
      "0.6635140776634216\n",
      "0.7237004041671753\n",
      "0.6641891598701477\n",
      "0.7240629196166992\n",
      "0.7237783074378967\n",
      "0.7241917848587036\n",
      "0.6611032485961914\n",
      "0.6623164415359497\n",
      "0.7249388098716736\n",
      "0.6634036898612976\n",
      "0.7241264581680298\n",
      "0.7239258289337158\n",
      "0.6622042059898376\n",
      "0.6612498760223389\n",
      "0.6633594036102295\n",
      "0.6616000533103943\n",
      "0.6625319123268127\n",
      "0.7234545946121216\n",
      "0.6611862778663635\n",
      "0.6628317832946777\n",
      "0.7244824767112732\n",
      "0.6618789434432983\n",
      "0.6625689268112183\n",
      "0.7264171242713928\n",
      "0.6615567207336426\n",
      "0.6592668890953064\n",
      "0.6616221070289612\n",
      "0.6624572277069092\n",
      "0.7261682152748108\n",
      "0.6592303514480591\n",
      "0.6589871048927307\n",
      "0.6612792015075684\n",
      "0.6574881672859192\n",
      "0.729127824306488\n",
      "0.728015124797821\n",
      "0.6559187173843384\n",
      "0.6571541428565979\n",
      "0.7303683161735535\n",
      "0.6582022905349731\n",
      "begin print\n",
      "Epoch 7; Step 700; Loss 0.658202; Train acc: 0.523438; Dev acc 0.515625\n",
      "0.6585951447486877\n",
      "0.6564229130744934\n",
      "0.7289823889732361\n",
      "0.7294460535049438\n",
      "0.6572797298431396\n",
      "0.6583382487297058\n",
      "0.7313036322593689\n",
      "0.6546204686164856\n",
      "0.6570761799812317\n",
      "0.7331536412239075\n",
      "0.6546269655227661\n",
      "0.7330660223960876\n",
      "0.7327733039855957\n",
      "0.6564200520515442\n",
      "0.6571258306503296\n",
      "0.7305953502655029\n",
      "0.7319347262382507\n",
      "0.7322626709938049\n",
      "0.658019483089447\n",
      "0.6548949480056763\n",
      "0.6570675373077393\n",
      "0.7333829402923584\n",
      "0.6548564434051514\n",
      "0.7318227887153625\n",
      "0.6568554043769836\n",
      "0.7311000823974609\n",
      "0.7317230701446533\n",
      "0.7326637506484985\n",
      "0.6546856164932251\n",
      "0.7327545881271362\n",
      "0.7306511998176575\n",
      "0.6541981101036072\n",
      "0.6578058004379272\n",
      "0.6552983522415161\n",
      "0.7295078635215759\n",
      "0.7296540141105652\n",
      "0.6563578844070435\n",
      "0.7330268621444702\n",
      "0.7301145792007446\n",
      "0.7309980392456055\n",
      "0.7322177886962891\n",
      "0.6551761031150818\n",
      "0.7316665649414062\n",
      "0.7316564321517944\n",
      "0.6569746732711792\n",
      "0.7291437387466431\n",
      "0.6569631695747375\n",
      "0.7300153374671936\n",
      "0.6590628027915955\n",
      "0.6569437384605408\n",
      "0.6565113067626953\n",
      "0.7278183698654175\n",
      "0.7258411645889282\n",
      "0.6576228737831116\n",
      "0.7293649911880493\n",
      "0.6592361330986023\n",
      "0.729658842086792\n",
      "0.6573198437690735\n",
      "0.7298800349235535\n",
      "0.7285847067832947\n",
      "0.6572074890136719\n",
      "0.7292428612709045\n",
      "0.7311227321624756\n",
      "0.6602038741111755\n",
      "0.7269986271858215\n",
      "0.726669192314148\n",
      "0.6587033867835999\n",
      "0.6603745818138123\n",
      "0.6593747138977051\n",
      "0.6609486937522888\n",
      "0.7258654236793518\n",
      "0.7262560725212097\n",
      "0.725348711013794\n",
      "0.7299122214317322\n",
      "0.6594305038452148\n",
      "0.7260016202926636\n",
      "0.7273460626602173\n",
      "0.725936233997345\n",
      "0.7234204411506653\n",
      "0.6599643230438232\n",
      "0.6631253361701965\n",
      "0.7259968519210815\n",
      "0.6617302298545837\n",
      "0.6603021025657654\n",
      "0.7247294187545776\n",
      "0.7261147499084473\n",
      "0.724399209022522\n",
      "0.7264506816864014\n",
      "0.6622157692909241\n",
      "0.6626588702201843\n",
      "0.7263097763061523\n",
      "0.7237881422042847\n",
      "0.6640447378158569\n",
      "0.6649012565612793\n",
      "0.662407636642456\n",
      "0.6609480977058411\n",
      "0.7216179370880127\n",
      "0.7242727875709534\n",
      "0.7240986824035645\n",
      "0.7210098505020142\n",
      "begin print\n",
      "Epoch 8; Step 800; Loss 0.721010; Train acc: 0.523438; Dev acc 0.515625\n",
      "0.7250131368637085\n",
      "0.7248449325561523\n",
      "0.7237372398376465\n",
      "0.7213925123214722\n",
      "0.6619864702224731\n",
      "0.6638244390487671\n",
      "0.7235382795333862\n",
      "0.7262999415397644\n",
      "0.7233331799507141\n",
      "0.6661589741706848\n",
      "0.6629898548126221\n",
      "0.6642684936523438\n",
      "0.6668391823768616\n",
      "0.6643510460853577\n",
      "0.7244352698326111\n",
      "0.6629588603973389\n",
      "0.6648056507110596\n",
      "0.6650675535202026\n",
      "0.665980875492096\n",
      "0.6658307909965515\n",
      "0.7243265509605408\n",
      "0.7188802361488342\n",
      "0.7248134613037109\n",
      "0.6624332070350647\n",
      "0.6633090376853943\n",
      "0.6631811857223511\n",
      "0.7244458198547363\n",
      "0.6656330227851868\n",
      "0.7240663170814514\n",
      "0.7234913110733032\n",
      "0.6648478507995605\n",
      "0.6612077355384827\n",
      "0.7238368391990662\n",
      "0.6638592481613159\n",
      "0.6627213358879089\n",
      "0.7216383814811707\n",
      "0.7271431684494019\n",
      "0.6617117524147034\n",
      "0.6639541983604431\n",
      "0.7256186008453369\n",
      "0.7230650186538696\n",
      "0.7245994806289673\n",
      "0.7246900200843811\n",
      "0.7225456833839417\n",
      "0.6618251800537109\n",
      "0.7244202494621277\n",
      "0.6622557640075684\n",
      "0.7249356508255005\n",
      "0.6620014309883118\n",
      "0.6630163788795471\n",
      "0.7228419780731201\n",
      "0.7238872051239014\n",
      "0.7237784266471863\n",
      "0.6618849039077759\n",
      "0.7203177809715271\n",
      "0.6653671264648438\n",
      "0.7215448021888733\n",
      "0.7229446768760681\n",
      "0.7252024412155151\n",
      "0.7220077514648438\n",
      "0.6639897227287292\n",
      "0.6638164520263672\n",
      "0.7196500301361084\n",
      "0.7224807739257812\n",
      "0.6637741923332214\n",
      "0.6644275188446045\n",
      "0.6635345816612244\n",
      "0.7190057635307312\n",
      "0.6655388474464417\n",
      "0.721163809299469\n",
      "0.7205750346183777\n",
      "0.7218038439750671\n",
      "0.666717529296875\n",
      "0.7199256420135498\n",
      "0.7212235331535339\n",
      "0.6661501526832581\n",
      "0.7205427289009094\n",
      "0.6685301661491394\n",
      "0.7225854992866516\n",
      "0.7198084592819214\n",
      "0.6655977964401245\n",
      "0.6687732934951782\n",
      "0.7160776257514954\n",
      "0.6673596501350403\n",
      "0.6654056310653687\n",
      "0.6677073836326599\n",
      "0.6681190133094788\n",
      "0.7212307453155518\n",
      "0.6679627299308777\n",
      "0.6713684797286987\n",
      "0.7214232683181763\n",
      "0.6678546667098999\n",
      "0.6672192811965942\n",
      "0.7171647548675537\n",
      "0.6681181788444519\n",
      "0.666885495185852\n",
      "0.7207059264183044\n",
      "0.6662037968635559\n",
      "0.7187948822975159\n",
      "0.7224404811859131\n",
      "begin print\n",
      "Epoch 9; Step 900; Loss 0.722440; Train acc: 0.523438; Dev acc 0.515625\n",
      "0.72248774766922\n",
      "0.7200976610183716\n",
      "0.7241997718811035\n",
      "0.7216320037841797\n",
      "0.6681554913520813\n",
      "0.6695154905319214\n",
      "0.7182807326316833\n",
      "0.667824923992157\n",
      "0.669439435005188\n",
      "0.6655036211013794\n",
      "0.7218208909034729\n",
      "0.7180306315422058\n",
      "0.6663724184036255\n",
      "0.6675081253051758\n",
      "0.667032778263092\n",
      "0.6686475276947021\n",
      "0.7209370732307434\n",
      "0.6699124574661255\n",
      "0.6649549007415771\n",
      "0.6657068133354187\n",
      "0.7225714921951294\n",
      "0.7203362584114075\n",
      "0.6648223400115967\n",
      "0.6663948893547058\n",
      "0.6645154356956482\n",
      "0.664909839630127\n",
      "0.6645216941833496\n",
      "0.7243218421936035\n",
      "0.7224258780479431\n",
      "0.7223057150840759\n",
      "0.7202946543693542\n",
      "0.6646596789360046\n",
      "0.7236411571502686\n",
      "0.6646866798400879\n",
      "0.7212280631065369\n",
      "0.724352240562439\n",
      "0.6642719507217407\n",
      "0.7243160605430603\n",
      "0.6636101603507996\n",
      "0.6645072102546692\n",
      "0.7253203988075256\n",
      "0.7230458855628967\n",
      "0.6638603210449219\n",
      "0.6652690768241882\n",
      "0.6651208996772766\n",
      "0.6642774939537048\n",
      "0.723304808139801\n",
      "0.724452018737793\n",
      "0.6641719937324524\n",
      "0.6615702509880066\n",
      "0.6645083427429199\n",
      "0.6637418866157532\n",
      "0.7233609557151794\n",
      "0.7244173288345337\n",
      "0.6653781533241272\n",
      "0.7224427461624146\n",
      "0.6627078056335449\n",
      "0.7248730063438416\n",
      "0.6637930274009705\n",
      "0.7231816053390503\n",
      "0.7258186936378479\n",
      "0.7214675545692444\n",
      "0.7234019041061401\n",
      "0.6618977785110474\n",
      "0.6649397611618042\n",
      "0.6649451851844788\n",
      "0.6633473634719849\n",
      "0.7241718173027039\n",
      "0.7231335639953613\n",
      "0.6634075045585632\n",
      "0.6627306938171387\n",
      "0.7232523560523987\n",
      "0.7237696051597595\n",
      "0.7244960069656372\n",
      "0.7201934456825256\n",
      "0.6642012000083923\n",
      "0.6641548871994019\n",
      "0.7208311557769775\n",
      "0.6628382205963135\n",
      "0.6637906432151794\n",
      "0.6644331812858582\n",
      "0.6657921671867371\n",
      "0.6641812920570374\n",
      "0.662471354007721\n",
      "0.6673393845558167\n",
      "0.7205544710159302\n",
      "0.7255905270576477\n",
      "0.7259491682052612\n",
      "0.6620825529098511\n",
      "0.7233522534370422\n",
      "0.7248348593711853\n",
      "0.7276320457458496\n",
      "0.6630722284317017\n",
      "0.6626598238945007\n",
      "0.6638960838317871\n",
      "0.726067304611206\n",
      "0.6614943742752075\n",
      "0.6628169417381287\n",
      "0.6631411910057068\n",
      "0.7254939675331116\n",
      "begin print\n",
      "Epoch 10; Step 1000; Loss 0.725494; Train acc: 0.523438; Dev acc 0.515625\n"
     ]
    }
   ],
   "source": [
    "tls.training_loop(batch_size, total_batches, alphabet_size, l0, num_epochs, model, loss, optimizer, \n",
    "              training_iter, validation_iter, train_eval_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
